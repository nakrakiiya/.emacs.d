<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/><link rel="stylesheet" href="lpdoc.css" type="text/css"/><title>Analytic benchmarks &mdash; The Ciao System v1.14#2</title></head><body><div class="nav"><span class="on_right"><a class="navbutton" href="ciaopaths_doc.html">&#x25C4;</a><a class="navbutton" href="getopts.html">&#x25BA;</a></span><span><a href="ciao.html">The Ciao System</a> &raquo; <a href="MiscProlog.html">PART VI - Ciao library miscellanea</a> &raquo; </span></div><div class="documentwrapper"><div class="document"><div class="mainwrapper"><div class="main"><div id=""><h1>Analytic benchmarks</h1><a class="idx_anchor" href="ciaoliindex.html#ecrc"></a>
<strong>Author(s):</strong> <a class="idx_anchor" id="Manuel Carro" href="ciaoauindex.html#Manuel Carro">Manuel Carro (adapted to Ciao Prolog)</a>.<p>
This module provides a set of analytic benchmarks which try to isolate and measure the speed of certain very common operations in a Prolog system. The benchmarks come from a variety of sources, mostly within former ECRC (please look at the comments in the source code) and were posted by Jean-Claude Syre on 24th June 1986 to the Prolog Digest. Further packaging was done by Thoma Sjoland and SICS. They were adapted to Ciao Prolog by Manuel Carro, by:<p><ul> <p><LI>Changing the syntax to Ciao Prolog, when needed, including extensive use of higher-order programming for the benchmarking loops.<p><LI>Adapting the size of the benchmarks and the number of repetitions to fit modern computers and Prolog compilation.<p><LI>Changing the format of the output and recording performance data in the incore database.<p><LI>Changing benchmarking loops to be failure-driven.<p><LI>Adding a void initial dry run to heat up the caches.<p></ul> <p>The comments corresponding to the <strong>original</strong> programs follow. They have been largely unchanged, except to reflect changes in the program interface necessary to perform the modularization and to adapt them to Ciao Prolog. Of course the number of repeated calls was changed. The original comments are still in the source files.<p><div id="Testing Calls"><h2>Testing Calls</h2> <p>This is the one you always dreamed to test! Like all benchmarks, it uses a loop calling the actual benchmark program. The benchmark program consists of a sequence of 200 predicates having no arguments, no choice points, NOTHING. 200 is chosen to have sufficient accuracy in measuring the execution time.<p>The results show the effect of pure calls, and the Klips performance can be called the peak performance of the prolog system. Note that the peak performance has very little significance to classify the overall performance of a Prolog system.<p></div><div id="Testing non-deterministic behavior"><h2>Testing non-deterministic behavior</h2> <p>This program contains a series of 3 different benchmark predicates.<p>The predicate <a class="idx_anchor" id="0" href="ciaoglindex.html#choice_point/1"><tt>choice_point/1</tt></a> tests calls invoking the creation of a choice point, i.e. a branch point where the execution will possibly come back to in case of backtracking. It does NOT backtrack. Two versions are proposed, one with and the other without arguments.<p>We then present two predicates to evaluate the mechanism of backtracking during execution. Both predicates create one choice_point and then backtrack 20 times on every loop iteration step. <a class="idx_anchor" id="1" href="ciaoglindex.html#baktrak1/1"><tt>baktrak1/1</tt></a> exhibits a kind of backtracking called <em>deep</em>, while <a class="idx_anchor" id="2" href="ciaoglindex.html#baktrak2/1"><tt>baktrak2/1</tt></a> deals with <em>shallow</em> backtracking. Both are worth being tried, whatever your particular Prolog System is.<p></div><div id="Testing environment handling"><h2>Testing environment handling</h2> <p>The creation and deletion of environments are an important feature in prolog machines. The following program attempts to evaluate that. A usual condition to have environments is that the clause is made of several goals. Thus there will be calls in the clause creating environments, and some work to set the parameters of each call. Three arguments per goal were chosen because this number comes close to the average number of arguments of a predicate and to the average number of permanent variables in an environment. The arguments were arranged in different orders for every goal, because we did not want to measure the merits of register transfer optimisations. Note that these transfers exist, so the results cannot be compared with those given by the program which creates choice points (generally slower).<p>Another version, <a class="idx_anchor" id="3" href="ciaoglindex.html#envir0ar/1"><tt>envir0ar/1</tt></a>, with 0 argument in each call, can also be usefully tried<p></div><div id="Testing indexing mechanisms"><h2>Testing indexing mechanisms</h2> <p>We give only one test for indexing, i.e. the selection of a clause due to the type of an argument. This program does not test the merits of indexing on an argument other than the first one. It does not test for multiple indexing either. It does not show the inefficiency which occurs if 2 choice points per clause are created. This may happen e.g. in Warren&apos;s indexing scheme.<p>Each of these tests would require an extra benchmark program. The program given below tests the main point in indexing. Right now we think it is not worth adding all this complexity to the benchmarks, in order to measure all the details in indexing. Therefore we give only this single test.<p></div><div id="Testing unification"><h2>Testing unification</h2> <p>We have 6 programs to evaluate the process of unification in the Prolog system:<p><ul> <p><LI>Test of list construction via unification.<p><LI>Test of list matching unification.<p><LI>Test of structure construction via unification This program is equivalent to construct_list, except that it uses the standard structure representation instead of the simplified list notation.<p><LI>Test of structure matching via unification. This predicate matches a list of 100 elements in structure notation.<p><LI>Test to match a nested structure. This predicate tests the (compiled) unification of a complex structure.<p><LI>Test of general unification of 2 complex structures. This predicate tests general unification. We call it general unification, because it cannot be analysed at compile time. Therefore this kind of unification cannot be compiled and, even in a compiled system, it must be handled at run time, exactly as by an interpreter. This is done by a general procedure for unification. The name of the benchmark therefore does not reflect that the unification is general, i.e. including all Prolog types (e.g. it does not contain variables), but it reflects the use of the procedure for general unification as opposed to specific, compiled unification.<p></ul> <p><em>Manuel Carro: note that in this case the term &quot;Logical Inference&quot; is a bit contrived, since by design some of these (head) unifications are very more compled, naturally being slower and giving slow KLIPS results.</em> <p></div><div id="Testing dereferencing"><h2>Testing dereferencing</h2> <p>Program to benchmark the dereferencing speed. It constructs a list containing 500 variables which are then bound together. Since different systems use different strategies for binding variables on the global stack, the whole is made for two lists and the long variable chain is created only in one of them.<p><em>Manuel Carro: different results in this benchmark are not likely to affect larger, general programs. It is a well-known fact that n programs tend not to generate long dereferencing chains. Empirical measurements show that dereference chains of length greater than three are extremely rare. So a suboptimal / optimal behavior in this test is not likely to affect greatly the overall speed of a system.</em> <p></div><div id="Testing the cut"><h2>Testing the cut</h2> <p> It seems almost impossible to isolate the cut operator in a simple test program. However, the cut-testing program in this benchmark set contains a lot of cut at exec time. It may be regarded as a partial test of cut, and may be worthwhile for some software implementations of Prolog. <a class="idx_anchor" id="4" href="ciaoglindex.html#cuttest/1"><tt>cuttest/1</tt></a> calls the cutit11 predicate, which performs 100 calls to a predicate cutt1 where a cut operator appears in the second clause. Having indexing makes the evaluation of the cut more accurate, so please indicate in our result whether or not your Prolog system uses indexing, to clarify the comparison with others.<p> </div><div id="Assorted small programs"><h2>Assorted small programs</h2> <p>Here we deal with prolog programs that do something, while being still small but representative of some well-known Prolog computations. This set should be augmented by other programs, some of them might come from your ideas.<p>Some of the following programs were taken from the Berkeley paper by Peter Van Roy &quot;A Prolog Compiler for the PLM&quot;. Other programs were kindly donated by the following ECRC members: Helmut Simonis, Mehmet Dincbas, Micha Meier and Pascal Van Hentenryck.<p>The programs have been statically analysed and they represent fairly standard programs as far as the statistical averages are concerned. That is the arity of most clauses is 2 or 3 and there are usually 2 or 3 clauses per predicate. The programs range from fairly trivial programs like fibonacci series to problems such as Hamiltonian graph traversal.<p>Also, some more programs have been added since the last release and some corrections have been made. Most of the writes were removed in order to reduce i/o activity.<p>The programs added were symbolic differentiation (from Warren&apos;s paper) and a quick sort algorithm using difference lists. The last addition is a bit of a rogue: its a naive reverse, where one can enter the list length. The list gets constructed and then gets reversed.<p>We are grateful to Saumya Debray from Stony Brook and others for comments, suggestions, feedback and useful inputs.<p>These benchmarks were run on a VAX 785 with 8 Meg of memory, under 4.2 BSD Unix. The interpreter was C-Prolog version 1.5.<p>This entire file (without mail/net headers) contains 584 lines.<p><pre>Name      |      Call by      |  # of Inferences  | KLips
          |                   |  (one iteration)  | (C-Prolog)
----------+-------------------+-------------------+-----------
fib       | fibonacci(1).     |        4932       |   2.0
----------+-------------------+-------------------+-----------
map       | map(200).         |          68       |   1.3
----------+-------------------+-------------------+-----------
mham      | mham(1).          |      493824       |   1.7
----------+-------------------+-------------------+-----------
mutest    | mutest(1).        |        1366       |   2.3
----------+-------------------+-------------------+-----------
quicksort | qs(10).           |         601       |   1.9
----------+-------------------+-------------------+-----------
queens    | qu(10).           |         684       |   1.7
----------+-------------------+-------------------+-----------
query     | query(1).         |        2294       |   0.9
----------+-------------------+-------------------+-----------
sym_diff  | differen(150).    |          71       |   1.5
----------+-------------------+-------------------+-----------
diff_lists| diff(50).         |         608       |   2.1
----------+-------------------+-------------------+-----------
nrev  10  | nrev.             |          66       |   2.0
----------+-------------------+-------------------+-----------
nrev  30  | nrev.             |         496       |   2.5
----------+-------------------+-------------------+-----------
nrev  50  | nrev.             |        1326       |   2.5
----------+-------------------+-------------------+-----------
nrev 100  | nrev.             |        5151       |   2.5
----------+-------------------+-------------------+-----------
nrev 150  | nrev.             |       11476       |   2.5
----------+-------------------+-------------------+-----------
nrev 200  | nrev.             |       20301       |   2.5
----------+-------------------+-------------------+-----------
</pre> <p></div><br/><div id="Usage and interface"><h2>Usage and interface</h2><div class="cartouche"><ul><LI><strong>Library usage:</strong><br/><tt>:- use_module(library(ecrc)).</tt><LI><strong>Exports:</strong><br/><ul class="itemize_minus"><LI><em>Predicates:</em><br/><a class="idx_anchor" id="5" href="ciaoglindex.html#main/1"><tt>main/1</tt></a>, <a class="idx_anchor" id="6" href="ciaoglindex.html#just_benchmarks/0"><tt>just_benchmarks/0</tt></a>, <a class="idx_anchor" id="7" href="ciaoglindex.html#generate_human_file/0"><tt>generate_human_file/0</tt></a>, <a class="idx_anchor" id="8" href="ciaoglindex.html#generate_machine_file/0"><tt>generate_machine_file/0</tt></a>, <a class="idx_anchor" id="9" href="ciaoglindex.html#send_info_to_developers/0"><tt>send_info_to_developers/0</tt></a>, <a class="idx_anchor" id="10" href="ciaoglindex.html#arithm_average/2"><tt>arithm_average/2</tt></a>, <a class="idx_anchor" id="11" href="ciaoglindex.html#geom_average/2"><tt>geom_average/2</tt></a>.
<LI><em>Regular Types:</em><br/><a class="idx_anchor" id="12" href="ciaoglindex.html#benchmark_usage/1"><tt>benchmark_usage/1</tt></a>.
</ul><LI><strong>Other modules used:</strong><br/><ul class="itemize_minus"><LI><em>System library modules:</em><br/><a class="idx_anchor" id="13" href="ciaoglindex.html#aggregates"><tt>aggregates</tt></a>, <a class="idx_anchor" id="14" href="ciaoglindex.html#format"><tt>format</tt></a>, <a class="idx_anchor" id="15" href="ciaoglindex.html#lists"><tt>lists</tt></a>, <a class="idx_anchor" id="16" href="ciaoglindex.html#system"><tt>system</tt></a>, <a class="idx_anchor" id="17" href="ciaoglindex.html#dec10_io"><tt>dec10_io</tt></a>, <a class="idx_anchor" id="18" href="ciaoglindex.html#terms"><tt>terms</tt></a>, <a class="idx_anchor" id="19" href="ciaoglindex.html#hiordlib"><tt>hiordlib</tt></a>, <a class="idx_anchor" id="20" href="ciaoglindex.html#getopts"><tt>getopts</tt></a>, <a class="idx_anchor" id="21" href="ciaoglindex.html#prolog_sys"><tt>prolog_sys</tt></a>, <a class="idx_anchor" id="22" href="ciaoglindex.html#benchmarks/benchmark_utilities"><tt>benchmarks/benchmark_utilities</tt></a>, <a class="idx_anchor" id="23" href="ciaoglindex.html#benchmarks/boresea"><tt>benchmarks/boresea</tt></a>, <a class="idx_anchor" id="24" href="ciaoglindex.html#benchmarks/choice"><tt>benchmarks/choice</tt></a>, <a class="idx_anchor" id="25" href="ciaoglindex.html#benchmarks/envir"><tt>benchmarks/envir</tt></a>, <a class="idx_anchor" id="26" href="ciaoglindex.html#benchmarks/index"><tt>benchmarks/index</tt></a>, <a class="idx_anchor" id="27" href="ciaoglindex.html#benchmarks/unif"><tt>benchmarks/unif</tt></a>, <a class="idx_anchor" id="28" href="ciaoglindex.html#benchmarks/deref"><tt>benchmarks/deref</tt></a>, <a class="idx_anchor" id="29" href="ciaoglindex.html#benchmarks/cut"><tt>benchmarks/cut</tt></a>, <a class="idx_anchor" id="30" href="ciaoglindex.html#benchmarks/small_programs"><tt>benchmarks/small_programs</tt></a>, <a class="idx_anchor" id="31" href="ciaoglindex.html#benchmarks/results"><tt>benchmarks/results</tt></a>.
</ul></ul></div></div><div id="Documentation on exports"><h2>Documentation on exports</h2><div><span class="on_right">PREDICATE</span><div class="defname"><a class="idx_anchor" id="main/1" href="ciaopdindex.html#main/1">main/1</a>:</div><div class="deftext"><p><strong>Usage:</strong> <tt>main(Flags)</tt>
<ul class="itemize_minus"><LI><em>Description:</em> Main entry point. Execute all benchmarks and report on the performance obtained. This makes it easy to run the set of benchmarks as an executable. Its behavior regarding printing gathered data can be controlled with the list of flags passed as argument. Data is <strong>always</strong> asserted and available to other programs through the <a class="idx_anchor" id="32" href="ciaoglindex.html#dump_benchmark_data/0"><tt>dump_benchmark_data/0</tt></a> and <a class="idx_anchor" id="33" href="ciaoglindex.html#access_benchmark_data/8"><tt>access_benchmark_data/8</tt></a> predicates.<LI><em>The following properties should hold at call time:</em><br/><span class="on_right"> (term_typing:nonvar/1)</span><span><span class="var">Flags</span> is currently a term which is not a free variable.
</span><br/><span class="on_right"> (basic_props:list/2)</span><span><span class="var">Flags</span> is a list of <span class="var">benchmark_usage</span>s.
</span>
</ul></div></div><p>
<div><span class="on_right">REGTYPE</span><div class="defname"><a class="idx_anchor" id="benchmark_usage/1" href="ciaoteindex.html#benchmark_usage/1">benchmark_usage/1</a>:</div><div class="deftext"><p><strong>Usage:</strong> <tt>benchmark_usage(Flag)</tt>
<ul class="itemize_minus"><LI><em>Description:</em> Options which determine what this module should do with the execution results when called through the <a class="idx_anchor" id="34" href="ciaoglindex.html#main/1"><tt>main/1</tt></a> entry point (i.e., if compiled to an executable). It is defined as<p><pre>benchmark_usage(&apos;--estimation&apos;).
benchmark_usage(&apos;--no-machine&apos;).
benchmark_usage(&apos;--no-human&apos;).
benchmark_usage(&apos;--send-info&apos;).
benchmark_usage(&apos;--base-file-name&apos;).
</pre> <p>with the following meaning:<p><ul> <p><LI><tt>&apos;--no-human&apos;</tt>: do <strong>not</strong> dump human-readable data.<p><LI><tt>&apos;--no-machine&apos;</tt>: do <strong>not</strong> dump data as a series of facts (which is a machine-readable format) which can be saved to a file and later read back in Prolog.<p><LI><tt>&apos;--send-info&apos;</tt>: send a mail to the Ciao developers with the information gathered plus a terse description of the machine (O.S., architecture, CPU type and speed). The existence of a suitable user command to send mail is expected. No message is sent otherwise. No sensible (personal, etc.) information is gathered or sent.<p><LI><tt>--base-file-name <em>file-name</em></tt>: use <em>file-name</em> as a base to generate file with the reports this module generates. The machine-oriented file will have the <tt>.pl</tt> extension and the human-oriented file will have the <tt>.txt</tt> extension.<p></ul> <p>The options aboce can be used when calling <a class="idx_anchor" id="35" href="ciaoglindex.html#main/1"><tt>main/1</tt></a> predicate or as command-line options for an executable built from this file. Note that the default options <strong>print</strong> available data both in human-readable and machine-readable formats.<LI><em>Call and exit should be compatible with:</em><br/><span class="on_right"> (basic_props:atm/1)</span><span><span class="var">Flag</span> is an atom.
</span>
</ul></div></div><p>
<div><span class="on_right">PREDICATE</span><div class="defname"><a class="idx_anchor" id="just_benchmarks/0" href="ciaopdindex.html#just_benchmarks/0">just_benchmarks/0</a>:</div><div class="deftext"><p><strong>Usage:</strong> <ul class="itemize_minus"><LI><em>Description:</em> Run the set of benchmarks in this program and save the speed information gathered. They can be later accessed using the predicates <a class="idx_anchor" id="36" href="ciaoglindex.html#generate_machine_file/0"><tt>generate_machine_file/0</tt></a> or <a class="idx_anchor" id="37" href="ciaoglindex.html#generate_human_file/0"><tt>generate_human_file/0</tt></a>.</ul></div></div><p>
<div><span class="on_right">PREDICATE</span><div class="defname"><a class="idx_anchor" id="generate_human_file/0" href="ciaopdindex.html#generate_human_file/0">generate_human_file/0</a>:</div><div class="deftext"><p><strong>Usage:</strong> <ul class="itemize_minus"><LI><em>Description:</em> Print to standard output a human-readable report of the information gathered by running <a class="idx_anchor" id="38" href="ciaoglindex.html#just_benchmarks/0"><tt>just_benchmarks/0</tt></a>.</ul></div></div><p>
<div><span class="on_right">PREDICATE</span><div class="defname"><a class="idx_anchor" id="generate_machine_file/0" href="ciaopdindex.html#generate_machine_file/0">generate_machine_file/0</a>:</div><div class="deftext"><p><strong>Usage:</strong> <ul class="itemize_minus"><LI><em>Description:</em> Print to standard output a machine-readable report of the information gathered by running <a class="idx_anchor" id="39" href="ciaoglindex.html#just_benchmarks/0"><tt>just_benchmarks/0</tt></a>.</ul></div></div><p>
<div><span class="on_right">PREDICATE</span><div class="defname"><a class="idx_anchor" id="send_info_to_developers/0" href="ciaopdindex.html#send_info_to_developers/0">send_info_to_developers/0</a>:</div><div class="deftext"><p><strong>Usage:</strong> <ul class="itemize_minus"><LI><em>Description:</em> Send a message to the Ciao developers with a report of the information gathered by running <a class="idx_anchor" id="40" href="ciaoglindex.html#just_benchmarks/0"><tt>just_benchmarks/0</tt></a>.</ul></div></div><p>
<div><span class="on_right">PREDICATE</span><div class="defname"><a class="idx_anchor" id="arithm_average/2" href="ciaopdindex.html#arithm_average/2">arithm_average/2</a>:</div><div class="deftext">No further documentation available for this predicate.</div></div><p>
<div><span class="on_right">PREDICATE</span><div class="defname"><a class="idx_anchor" id="geom_average/2" href="ciaopdindex.html#geom_average/2">geom_average/2</a>:</div><div class="deftext">No further documentation available for this predicate.</div></div><p>
</div><div id="Known bugs and planned improvements"><h2>Known bugs and planned improvements</h2><ul><LI>The actual logical inferences each benchmark does has to be checked.</ul></div></div></div></div></div><div class="sidebarwrapper"><div class="sidebar"><IMG SRC="autofigciao-shadow-64h.png"><h2>Module Sections</h2><ul><LI><a href="#Testing Calls">Testing Calls</a><LI><a href="#Testing non-deterministic behavior">Testing non-deterministic behavior</a><LI><a href="#Testing environment handling">Testing environment handling</a><LI><a href="#Testing indexing mechanisms">Testing indexing mechanisms</a><LI><a href="#Testing unification">Testing unification</a><LI><a href="#Testing dereferencing">Testing dereferencing</a><LI><a href="#Testing the cut">Testing the cut</a><LI><a href="#Assorted small programs">Assorted small programs</a><LI><a href="#Usage and interface">Usage and interface</a><LI><a href="#Documentation on exports">Documentation on exports</a><LI><a href="#Known bugs and planned improvements">Known bugs and planned improvements</a></ul><h2>Global Links</h2><ul><LI><a href="ciaofulltoc.html">Table of Contents</a><LI><a href="ciaochanges.html">Version/Change Log</a><LI><a href="ciaorefs.html">References</a><LI><a href="ciaocopyright.html">Copyright</a></ul><h2>Indices</h2><ul><LI><a href="ciaoliindex.html">Library/Module Index</a><LI><a href="ciaopdindex.html">Predicate/Method Index</a><LI><a href="ciaoprindex.html">Property Index</a><LI><a href="ciaoteindex.html">Regular Type Index</a><LI><a href="ciaodeindex.html">Declaration Index</a><LI><a href="ciaocoindex.html">Concept Index</a><LI><a href="ciaoauindex.html">Author Index</a><LI><a href="ciaoglindex.html">Global Index</a></ul></div></div><div class="clearer"></div></div><div class="nav"><span class="on_right"><a class="navbutton" href="ciaopaths_doc.html">&#x25C4;</a><a class="navbutton" href="getopts.html">&#x25BA;</a></span><span>&nbsp;</span></div><div class="footer">Generated with LPdoc using Ciao</div></body></html>